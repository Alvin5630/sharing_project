{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for Kaggle Toxic Comments Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook for the kaggle toxic comments prediction competition:\n",
    "    [lin kere](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\", delimiter = \",\")\n",
    "test_df = pd.read_csv(\"test.csv\", delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_text = train_df['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                159571\n",
       "unique                                               159571\n",
       "top       \"\\n\\nAn invitation for you!\\n\\n . You're invit...\n",
       "freq                                                      1\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toxic = train_df['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 144277.,       0.,       0.,       0.,       0.,       0.,\n",
       "              0.,       0.,       0.,   15294.]),\n",
       " array([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAFXRJREFUeJzt3W2wXdV93/HvL1LwQxIMmIvrSnJE\naiWNzLRjrMFKM5O6VgICZxAvoCMmKYqrqaYEp2maNsb1C3VsM4ObtrTMYFLFqAiPa0xIWjSxqKrB\neNx2AHNtYh5DdYNduIGYa0umbhnbkfPvi7PknlyO7l3cc6UjWd/PzJmz93+tvfdauhf9tB/OIVWF\nJEk9fmjSA5AknToMDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3VZOegDL7dxz\nz621a9dOehiSdEr54he/+PWqmlqs3w9caKxdu5bp6elJD0OSTilJ/ldPPy9PSZK6GRqSpG6GhiSp\nm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkrr9wH0ifBxrr//MxI791RvfM7FjS1IvzzQkSd0W\nDY0ku5O8mOTxEW3/NEklObetJ8nNSWaSPJrkwqG+25IcbK9tQ/V3JHmsbXNzkrT6OUkOtP4Hkpy9\nPFOWJC1Vz5nG7cDm+cUka4BfAJ4dKl8KrGuvHcCtre85wE7gncBFwM6hELi19T263dFjXQ/cV1Xr\ngPvauiRpghYNjar6PHBoRNNNwG8BNVTbAtxRAw8CZyV5M3AJcKCqDlXVYeAAsLm1nVlVD1RVAXcA\nVwzta09b3jNUlyRNyJLuaSS5HPjTqvryvKZVwHND67OttlB9dkQd4E1V9QJAez9vKWOVJC2fV/30\nVJLXAx8ELh7VPKJWS6i/2jHtYHCJi7e85S2vdnNJUqelnGn8NeB84MtJvgqsBr6U5K8wOFNYM9R3\nNfD8IvXVI+oAX2uXr2jvLx5rQFW1q6o2VNWGqalF/8dTkqQletWhUVWPVdV5VbW2qtYy+Iv/wqr6\nM2AvcE17imoj8FK7tLQfuDjJ2e0G+MXA/tb2rSQb21NT1wD3tEPtBY4+ZbVtqC5JmpCeR24/BTwA\n/FSS2STbF+i+D3gGmAF+F/hVgKo6BHwYeLi9PtRqANcCH2/b/Alwb6vfCPxCkoMMntK68dVNTZK0\n3Ba9p1FVVy/SvnZouYDrjtFvN7B7RH0auGBE/RvApsXGJ0k6cfxEuCSpm6EhSepmaEiSuhkakqRu\nhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRu\nhoYkqZuhIUnqZmhIkroZGpKkbouGRpLdSV5M8vhQ7beT/HGSR5P8pyRnDbV9IMlMkqeTXDJU39xq\nM0muH6qfn+ShJAeTfDrJGa3+mrY+09rXLtekJUlL03OmcTuweV7tAHBBVf0N4H8CHwBIsh7YCryt\nbfOxJCuSrABuAS4F1gNXt74AHwVuqqp1wGFge6tvBw5X1VuBm1o/SdIELRoaVfV54NC82n+tqiNt\n9UFgdVveAtxZVd+pqq8AM8BF7TVTVc9U1XeBO4EtSQK8G7i7bb8HuGJoX3va8t3AptZfkjQhy3FP\n4+8D97blVcBzQ22zrXas+huBbw4F0NH6X9pXa3+p9ZckTchYoZHkg8AR4JNHSyO61RLqC+1r1Dh2\nJJlOMj03N7fwoCVJS7bk0EiyDfhF4Jeq6uhf5rPAmqFuq4HnF6h/HTgrycp59b+0r9b+BuZdJjuq\nqnZV1Yaq2jA1NbXUKUmSFrGk0EiyGXg/cHlVvTzUtBfY2p58Oh9YB3wBeBhY156UOoPBzfK9LWzu\nB65s228D7hna17a2fCXw2aFwkiRNwMrFOiT5FPAu4Nwks8BOBk9LvQY40O5NP1hV/7CqnkhyF/Ak\ng8tW11XV99p+3gfsB1YAu6vqiXaI9wN3JvkI8AhwW6vfBnwiyQyDM4ytyzBfSdIYFg2Nqrp6RPm2\nEbWj/W8AbhhR3wfsG1F/hsHTVfPr3wauWmx8kqQTx0+ES5K6GRqSpG6GhiSpm6EhSepmaEiSuhka\nkqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhka\nkqRuhoYkqZuhIUnqtmhoJNmd5MUkjw/VzklyIMnB9n52qyfJzUlmkjya5MKhbba1/geTbBuqvyPJ\nY22bm5NkoWNIkian50zjdmDzvNr1wH1VtQ64r60DXAqsa68dwK0wCABgJ/BO4CJg51AI3Nr6Ht1u\n8yLHkCRNyKKhUVWfBw7NK28B9rTlPcAVQ/U7auBB4KwkbwYuAQ5U1aGqOgwcADa3tjOr6oGqKuCO\nefsadQxJ0oQs9Z7Gm6rqBYD2fl6rrwKeG+o322oL1WdH1Bc6xisk2ZFkOsn03NzcEqckSVrMct8I\nz4haLaH+qlTVrqraUFUbpqamXu3mkqROSw2Nr7VLS7T3F1t9Flgz1G818Pwi9dUj6gsdQ5I0IUsN\njb3A0SegtgH3DNWvaU9RbQReapeW9gMXJzm73QC/GNjf2r6VZGN7auqaefsadQxJ0oSsXKxDkk8B\n7wLOTTLL4CmoG4G7kmwHngWuat33AZcBM8DLwHsBqupQkg8DD7d+H6qqozfXr2XwhNbrgHvbiwWO\nIUmakEVDo6quPkbTphF9C7juGPvZDeweUZ8GLhhR/8aoY0iSJsdPhEuSuhkakqRuhoYkqZuhIUnq\nZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnq\nZmhIkroZGpKkboaGJKnbWKGR5DeSPJHk8SSfSvLaJOcneSjJwSSfTnJG6/uatj7T2tcO7ecDrf50\nkkuG6ptbbSbJ9eOMVZI0viWHRpJVwD8CNlTVBcAKYCvwUeCmqloHHAa2t022A4er6q3ATa0fSda3\n7d4GbAY+lmRFkhXALcClwHrg6tZXkjQh416eWgm8LslK4PXAC8C7gbtb+x7gira8pa3T2jclSavf\nWVXfqaqvADPARe01U1XPVNV3gTtbX0nShCw5NKrqT4F/BTzLICxeAr4IfLOqjrRus8CqtrwKeK5t\ne6T1f+Nwfd42x6pLkiZknMtTZzP4l//5wF8FfoTBpaT56ugmx2h7tfVRY9mRZDrJ9Nzc3GJDlyQt\n0TiXp34e+EpVzVXVnwN/APwt4Kx2uQpgNfB8W54F1gC09jcAh4br87Y5Vv0VqmpXVW2oqg1TU1Nj\nTEmStJBxQuNZYGOS17d7E5uAJ4H7gStbn23APW15b1untX+2qqrVt7anq84H1gFfAB4G1rWnsc5g\ncLN87xjjlSSNaeXiXUarqoeS3A18CTgCPALsAj4D3JnkI612W9vkNuATSWYYnGFsbft5IsldDALn\nCHBdVX0PIMn7gP0MnszaXVVPLHW8kqTxLTk0AKpqJ7BzXvkZBk8+ze/7beCqY+znBuCGEfV9wL5x\nxihJWj5+IlyS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ\n3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUrexQiPJWUnuTvLHSZ5K\n8jNJzklyIMnB9n5265skNyeZSfJokguH9rOt9T+YZNtQ/R1JHmvb3Jwk44xXkjSecc80/h3wX6rq\nrwN/E3gKuB64r6rWAfe1dYBLgXXttQO4FSDJOcBO4J3ARcDOo0HT+uwY2m7zmOOVJI1hyaGR5Ezg\n54DbAKrqu1X1TWALsKd12wNc0Za3AHfUwIPAWUneDFwCHKiqQ1V1GDgAbG5tZ1bVA1VVwB1D+5Ik\nTcA4Zxo/AcwB/yHJI0k+nuRHgDdV1QsA7f281n8V8NzQ9rOttlB9dkRdkjQh44TGSuBC4Naqejvw\nf/n/l6JGGXU/opZQf+WOkx1JppNMz83NLTxqSdKSjRMas8BsVT3U1u9mECJfa5eWaO8vDvVfM7T9\nauD5ReqrR9Rfoap2VdWGqtowNTU1xpQkSQtZcmhU1Z8BzyX5qVbaBDwJ7AWOPgG1DbinLe8FrmlP\nUW0EXmqXr/YDFyc5u90AvxjY39q+lWRje2rqmqF9SZImYOWY2/8a8MkkZwDPAO9lEER3JdkOPAtc\n1fruAy4DZoCXW1+q6lCSDwMPt34fqqpDbfla4HbgdcC97SVJmpCxQqOq/gjYMKJp04i+BVx3jP3s\nBnaPqE8DF4wzRknS8vET4ZKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRu\nhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuo0dGklW\nJHkkyR+29fOTPJTkYJJPJzmj1V/T1mda+9qhfXyg1Z9OcslQfXOrzSS5ftyxSpLGsxxnGr8OPDW0\n/lHgpqpaBxwGtrf6duBwVb0VuKn1I8l6YCvwNmAz8LEWRCuAW4BLgfXA1a2vJGlCxgqNJKuB9wAf\nb+sB3g3c3brsAa5oy1vaOq19U+u/Bbizqr5TVV8BZoCL2mumqp6pqu8Cd7a+kqQJGfdM498CvwX8\nRVt/I/DNqjrS1meBVW15FfAcQGt/qfX/fn3eNseqv0KSHUmmk0zPzc2NOSVJ0rEsOTSS/CLwYlV9\ncbg8omst0vZq668sVu2qqg1VtWFqamqBUUuSxrFyjG1/Frg8yWXAa4EzGZx5nJVkZTubWA083/rP\nAmuA2SQrgTcAh4bqRw1vc6y6JGkClnymUVUfqKrVVbWWwY3sz1bVLwH3A1e2btuAe9ry3rZOa/9s\nVVWrb21PV50PrAO+ADwMrGtPY53RjrF3qeOVJI1vnDONY3k/cGeSjwCPALe1+m3AJ5LMMDjD2ApQ\nVU8kuQt4EjgCXFdV3wNI8j5gP7AC2F1VTxyH8UqSOi1LaFTV54DPteVnGDz5NL/Pt4GrjrH9DcAN\nI+r7gH3LMUZJ0vj8RLgkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6Eh\nSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6LTk0kqxJcn+Sp5I8\nkeTXW/2cJAeSHGzvZ7d6ktycZCbJo0kuHNrXttb/YJJtQ/V3JHmsbXNzkowzWUnSeMY50zgC/GZV\n/TSwEbguyXrgeuC+qloH3NfWAS4F1rXXDuBWGIQMsBN4J3ARsPNo0LQ+O4a22zzGeCVJY1pyaFTV\nC1X1pbb8LeApYBWwBdjTuu0BrmjLW4A7auBB4KwkbwYuAQ5U1aGqOgwcADa3tjOr6oGqKuCOoX1J\nkiZgWe5pJFkLvB14CHhTVb0Ag2ABzmvdVgHPDW0222oL1WdH1CVJEzJ2aCT5UeD3gX9cVf97oa4j\narWE+qgx7EgynWR6bm5usSFLkpZorNBI8sMMAuOTVfUHrfy1dmmJ9v5iq88Ca4Y2Xw08v0h99Yj6\nK1TVrqraUFUbpqamxpmSJGkB4zw9FeA24Kmq+jdDTXuBo09AbQPuGapf056i2gi81C5f7QcuTnJ2\nuwF+MbC/tX0rycZ2rGuG9iVJmoCVY2z7s8DfAx5L8ket9s+BG4G7kmwHngWuam37gMuAGeBl4L0A\nVXUoyYeBh1u/D1XVobZ8LXA78Drg3vaSJE3IkkOjqv47o+87AGwa0b+A646xr93A7hH1aeCCpY5R\nkrS8/ES4JKmboSFJ6jbOPQ1J0jxrr//MxI791Rvfc9yP4ZmGJKmboSFJ6mZoSJK6GRqSpG6GhiSp\nm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSp\n20kfGkk2J3k6yUyS6yc9Hkk6nZ3UoZFkBXALcCmwHrg6yfrJjkqSTl8ndWgAFwEzVfVMVX0XuBPY\nMuExSdJp62QPjVXAc0Prs60mSZqAlZMewCIyolav6JTsAHa01f+T5OklHu9c4OtL3HYs+egkjgpM\ncM4T5JxPD6fdnPPRseb84z2dTvbQmAXWDK2vBp6f36mqdgG7xj1Ykumq2jDufk4lzvn04JxPDydi\nzif75amHgXVJzk9yBrAV2DvhMUnSaeukPtOoqiNJ3gfsB1YAu6vqiQkPS5JOWyd1aABU1T5g3wk6\n3NiXuE5Bzvn04JxPD8d9zql6xX1lSZJGOtnvaUiSTiKnZWgs9tUkSV6T5NOt/aEka0/8KJdXx5z/\nSZInkzya5L4kXY/fncx6v4ImyZVJKskp/aRNz3yT/N32c34iyX880WNcbh2/129Jcn+SR9rv9mWT\nGOdySrI7yYtJHj9Ge5Lc3P5MHk1y4bIOoKpOqxeDG+p/AvwEcAbwZWD9vD6/CvxOW94KfHrS4z4B\nc/47wOvb8rWnw5xbvx8DPg88CGyY9LiP8894HfAIcHZbP2/S4z4Bc94FXNuW1wNfnfS4l2HePwdc\nCDx+jPbLgHsZfM5tI/DQch7/dDzT6Plqki3AnrZ8N7ApyagPGp4qFp1zVd1fVS+31QcZfCbmVNb7\nFTQfBv4l8O0TObjjoGe+/wC4paoOA1TViyd4jMutZ84FnNmW38CIz3mdaqrq88ChBbpsAe6ogQeB\ns5K8ebmOfzqGRs9Xk3y/T1UdAV4C3nhCRnd8vNqvY9nO4F8qp7JF55zk7cCaqvrDEzmw46TnZ/yT\nwE8m+R9JHkyy+YSN7vjomfO/AH45ySyDpzB/7cQMbaKO69cvnfSP3B4HPV9N0vX1JaeQ7vkk+WVg\nA/C3j+uIjr8F55zkh4CbgF85UQM6znp+xisZXKJ6F4Mzyf+W5IKq+uZxHtvx0jPnq4Hbq+pfJ/kZ\n4BNtzn9x/Ic3Mcf176/T8Uyj56tJvt8nyUoGp7ULnQ6e7Lq+jiXJzwMfBC6vqu+coLEdL4vN+ceA\nC4DPJfkqg2u/e0/hm+G9v9f3VNWfV9VXgKcZhMipqmfO24G7AKrqAeC1DL6T6gdZ13/vS3U6hkbP\nV5PsBba15SuBz1a7w3SKWnTO7VLNv2cQGKf6tW5YZM5V9VJVnVtVa6tqLYP7OJdX1fRkhju2nt/r\n/8zggQeSnMvgctUzJ3SUy6tnzs8CmwCS/DSD0Jg7oaM88fYC17SnqDYCL1XVC8u189Pu8lQd46tJ\nknwImK6qvcBtDE5jZxicYWyd3IjH1znn3wZ+FPi9ds//2aq6fGKDHlPnnH9gdM53P3BxkieB7wH/\nrKq+MblRj6dzzr8J/G6S32BwieZXTvF/AJLkUwwuMZ7b7tXsBH4YoKp+h8G9m8uAGeBl4L3LevxT\n/M9PknQCnY6XpyRJS2RoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqdv/A3Ke4e32nLvq\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22f00fd16a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(toxic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_text = train_df['comment_text']\n",
    "test_text = test_df['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer=\"word\", ngram_range=(1,3), \\\n",
    "                            stop_words=\"english\", dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_vec = vectorizer.fit_transform(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_vec = vectorizer.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 6809271)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 6809271)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction for Toxic or Not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toxic_Y_train = train_df['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_vec, toxic_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.109999999999999"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_log = round(logreg.score(train_vec, toxic_Y_train) * 100, 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toxic_pred = logreg.predict_proba(test_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get All the Target Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
       "       'insult', 'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets = ['toxic', 'severe_toxic', 'obscene', 'threat',\n",
    "       'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.099999999999994"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and test severe_toxic\n",
    "severe_toxic_Y_train = train_df['severe_toxic']\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_vec, severe_toxic_Y_train)\n",
    "acc_log = round(logreg.score(train_vec, severe_toxic_Y_train) * 100, 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "severe_toxic_pred = logreg.predict_proba(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.420000000000002"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#targets = ['toxic', 'severe_toxic', 'obscene', 'threat',\n",
    "#       'insult', 'identity_hate']\n",
    "# Train and test obscene\n",
    "obscene_Y_train = train_df['obscene']\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_vec, obscene_Y_train)\n",
    "obscene_pred = logreg.predict_proba(test_vec)\n",
    "acc_log = round(logreg.score(train_vec, obscene_Y_train) * 100, 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.700000000000003"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#targets = ['toxic', 'severe_toxic', 'obscene', 'threat',\n",
    "#       'insult', 'identity_hate']\n",
    "# Train and test obscene\n",
    "threat_Y_train = train_df['threat']\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_vec, threat_Y_train)\n",
    "threat_pred = logreg.predict_proba(test_vec)\n",
    "acc_log = round(logreg.score(train_vec, threat_Y_train) * 100, 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.920000000000002"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#targets = ['toxic', 'severe_toxic', 'obscene', 'threat',\n",
    "#       'insult', 'identity_hate']\n",
    "# Train and test obscene\n",
    "insult_Y_train = train_df['insult']\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_vec, insult_Y_train)\n",
    "insult_pred = logreg.predict_proba(test_vec)\n",
    "acc_log = round(logreg.score(train_vec, insult_Y_train) * 100, 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.170000000000002"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#targets = ['toxic', 'severe_toxic', 'obscene', 'threat',\n",
    "#       'insult', 'identity_hate']\n",
    "# Train and test obscene\n",
    "identity_hate_Y_train = train_df['identity_hate']\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_vec, identity_hate_Y_train)\n",
    "identity_hate_pred = logreg.predict_proba(test_vec)\n",
    "acc_log = round(logreg.score(train_vec, identity_hate_Y_train) * 100, 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_array = np.zeros((test_text.shape[0], len(targets)), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 6)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00191909,  0.99808091],\n",
       "       [ 0.97350821,  0.02649179],\n",
       "       [ 0.96253087,  0.03746913],\n",
       "       [ 0.99273206,  0.00726794],\n",
       "       [ 0.94995214,  0.05004786]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_array[:,0] = toxic_pred[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_array[:,1] = severe_toxic_pred[:,1]\n",
    "submission_array[:,2] = obscene_pred[:,1]\n",
    "submission_array[:,3] = threat_pred[:,1]\n",
    "submission_array[:,4] = insult_pred[:,1]\n",
    "submission_array[:,5] = identity_hate_pred[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(submission_array, columns=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.998081</td>\n",
       "      <td>0.307892</td>\n",
       "      <td>0.996951</td>\n",
       "      <td>0.019316</td>\n",
       "      <td>0.981927</td>\n",
       "      <td>0.267294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026492</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.016811</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.018727</td>\n",
       "      <td>0.006227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.037469</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.018796</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>0.020865</td>\n",
       "      <td>0.006129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007268</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>0.006419</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.006798</td>\n",
       "      <td>0.002997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.050048</td>\n",
       "      <td>0.003947</td>\n",
       "      <td>0.019697</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.020432</td>\n",
       "      <td>0.004149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      toxic  severe_toxic   obscene    threat    insult  identity_hate\n",
       "0  0.998081      0.307892  0.996951  0.019316  0.981927       0.267294\n",
       "1  0.026492      0.005508  0.016811  0.002657  0.018727       0.006227\n",
       "2  0.037469      0.005375  0.018796  0.002481  0.020865       0.006129\n",
       "3  0.007268      0.003486  0.006419  0.001984  0.006798       0.002997\n",
       "4  0.050048      0.003947  0.019697  0.002443  0.020432       0.004149"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_df[\"id\"] = test_df[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.998081</td>\n",
       "      <td>0.307892</td>\n",
       "      <td>0.996951</td>\n",
       "      <td>0.019316</td>\n",
       "      <td>0.981927</td>\n",
       "      <td>0.267294</td>\n",
       "      <td>00001cee341fdb12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026492</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.016811</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.018727</td>\n",
       "      <td>0.006227</td>\n",
       "      <td>0000247867823ef7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.037469</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.018796</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>0.020865</td>\n",
       "      <td>0.006129</td>\n",
       "      <td>00013b17ad220c46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007268</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>0.006419</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.006798</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>00017563c3f7919a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.050048</td>\n",
       "      <td>0.003947</td>\n",
       "      <td>0.019697</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.020432</td>\n",
       "      <td>0.004149</td>\n",
       "      <td>00017695ad8997eb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      toxic  severe_toxic   obscene    threat    insult  identity_hate  \\\n",
       "0  0.998081      0.307892  0.996951  0.019316  0.981927       0.267294   \n",
       "1  0.026492      0.005508  0.016811  0.002657  0.018727       0.006227   \n",
       "2  0.037469      0.005375  0.018796  0.002481  0.020865       0.006129   \n",
       "3  0.007268      0.003486  0.006419  0.001984  0.006798       0.002997   \n",
       "4  0.050048      0.003947  0.019697  0.002443  0.020432       0.004149   \n",
       "\n",
       "                 id  \n",
       "0  00001cee341fdb12  \n",
       "1  0000247867823ef7  \n",
       "2  00013b17ad220c46  \n",
       "3  00017563c3f7919a  \n",
       "4  00017695ad8997eb  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', 'id']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cols = submission_df.columns.tolist()\n",
    "new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = new_cols[-1:] + new_cols[:-1] \n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_df = submission_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.998081</td>\n",
       "      <td>0.307892</td>\n",
       "      <td>0.996951</td>\n",
       "      <td>0.019316</td>\n",
       "      <td>0.981927</td>\n",
       "      <td>0.267294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.026492</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.016811</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.018727</td>\n",
       "      <td>0.006227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.037469</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.018796</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>0.020865</td>\n",
       "      <td>0.006129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.007268</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>0.006419</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.006798</td>\n",
       "      <td>0.002997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.050048</td>\n",
       "      <td>0.003947</td>\n",
       "      <td>0.019697</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.020432</td>\n",
       "      <td>0.004149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.998081      0.307892  0.996951  0.019316  0.981927   \n",
       "1  0000247867823ef7  0.026492      0.005508  0.016811  0.002657  0.018727   \n",
       "2  00013b17ad220c46  0.037469      0.005375  0.018796  0.002481  0.020865   \n",
       "3  00017563c3f7919a  0.007268      0.003486  0.006419  0.001984  0.006798   \n",
       "4  00017695ad8997eb  0.050048      0.003947  0.019697  0.002443  0.020432   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.267294  \n",
       "1       0.006227  \n",
       "2       0.006129  \n",
       "3       0.002997  \n",
       "4       0.004149  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_file = \"logisticregression.submission\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions on Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 8)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features = 6007, analyzer=\"word\", ngram_range=(1,3), \\\n",
    "                            stop_words=\"english\", dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train_sentences.clean'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-933f51632f0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mf_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train_sentences.clean\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf_in\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_sentences.clean'"
     ]
    }
   ],
   "source": [
    "train_text = []\n",
    "f_in = open(\"train_sentences.clean\", \"r\")\n",
    "while True:\n",
    "    sent = f_in.readline()\n",
    "    if sent == \"\":\n",
    "        break\n",
    "    train_text.append(sent)\n",
    "len(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test_sentences.clean'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-ca31f107b026>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mf_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_sentences.clean\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf_in\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msent\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_sentences.clean'"
     ]
    }
   ],
   "source": [
    "test_text = []\n",
    "f_in = open(\"test_sentences.clean\", \"r\")\n",
    "while True:\n",
    "    sent = f_in.readline()\n",
    "    if sent == \"\":\n",
    "        break\n",
    "    test_text.append(sent)\n",
    "len(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-6cf8090242d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\---------study\\Anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1379\u001b[0m             \u001b[0mTf\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0midf\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mweighted\u001b[0m \u001b[0mdocument\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mterm\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1380\u001b[0m         \"\"\"\n\u001b[1;32m-> 1381\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1382\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m         \u001b[1;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\---------study\\Anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[1;32m--> 869\u001b[1;33m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[0;32m    870\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\---------study\\Anaconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m                 raise ValueError(\"empty vocabulary; perhaps the documents only\"\n\u001b[0m\u001b[0;32m    812\u001b[0m                                  \" contain stop words\")\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "train_vec = vectorizer.fit_transform(train_text)\n",
    "test_vec = vectorizer.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 6007)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 6007)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = train_df['toxic']\n",
    "random_forest.fit(train_vec, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.74"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_log = round(random_forest.score(train_vec, Y_train) * 100, 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = random_forest.predict_proba(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08, 0.92],\n",
       "       [0.99, 0.01],\n",
       "       [1.  , 0.  ],\n",
       "       [0.99, 0.01],\n",
       "       [1.  , 0.  ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'explanation why the edits made under my username hardcore metallica fan were reverted   they were nt vandalisms   just closure on some gas after i voted at new york dolls fac   and please do nt remove the template from the talk page since i am retired now NUM\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets = ['toxic', 'severe_toxic', 'obscene', 'threat',\n",
    "       'insult', 'identity_hate']\n",
    "preds = np.zeros((test_vec.shape[0], len(targets)), dtype = np.float32)\n",
    "\n",
    "for idx, target in enumerate(targets):\n",
    "    Y_train = train_df[target]\n",
    "    random_forest.fit(train_vec, Y_train)\n",
    "    Y_pred = random_forest.predict_proba(test_vec)\n",
    "    preds[:, idx] = Y_pred[:, 1]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.92 , 0.235, 0.874, 0.06 , 0.77 , 0.17 ],\n",
       "       [0.02 , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.   , 0.   ],\n",
       "       [0.01 , 0.   , 0.   , 0.01 , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 0.   , 0.   , 0.01 , 0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_submissions = pd.DataFrame(preds, columns = targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "0   0.92         0.235    0.874    0.06    0.77           0.17\n",
       "1   0.02         0.000    0.000    0.00    0.00           0.00\n",
       "2   0.00         0.000    0.000    0.00    0.00           0.00\n",
       "3   0.01         0.000    0.000    0.01    0.00           0.00\n",
       "4   0.00         0.000    0.000    0.00    0.01           0.00"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_submissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_submissions[\"id\"] = test_df[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.17</td>\n",
       "      <td>00001cee341fdb12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0000247867823ef7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>00013b17ad220c46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>00017563c3f7919a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>00017695ad8997eb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "0   0.92         0.235    0.874    0.06    0.77           0.17   \n",
       "1   0.02         0.000    0.000    0.00    0.00           0.00   \n",
       "2   0.00         0.000    0.000    0.00    0.00           0.00   \n",
       "3   0.01         0.000    0.000    0.01    0.00           0.00   \n",
       "4   0.00         0.000    0.000    0.00    0.01           0.00   \n",
       "\n",
       "                 id  \n",
       "0  00001cee341fdb12  \n",
       "1  0000247867823ef7  \n",
       "2  00013b17ad220c46  \n",
       "3  00017563c3f7919a  \n",
       "4  00017695ad8997eb  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_submissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reordered_cols = [\"id\"] + targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_submissions = rf_submissions[reordered_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  toxic  severe_toxic  obscene  threat  insult  \\\n",
       "0  00001cee341fdb12   0.92         0.235    0.874    0.06    0.77   \n",
       "1  0000247867823ef7   0.02         0.000    0.000    0.00    0.00   \n",
       "2  00013b17ad220c46   0.00         0.000    0.000    0.00    0.00   \n",
       "3  00017563c3f7919a   0.01         0.000    0.000    0.01    0.00   \n",
       "4  00017695ad8997eb   0.00         0.000    0.000    0.00    0.01   \n",
       "\n",
       "   identity_hate  \n",
       "0           0.17  \n",
       "1           0.00  \n",
       "2           0.00  \n",
       "3           0.00  \n",
       "4           0.00  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_submissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_file = \"random_forests.submission\"\n",
    "rf_submissions.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression on Cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "targets = ['toxic', 'severe_toxic', 'obscene', 'threat',\n",
    "       'insult', 'identity_hate']\n",
    "logreg_preds = np.zeros((test_vec.shape[0], len(targets)), dtype = np.float32)\n",
    "\n",
    "for idx, target in enumerate(targets):\n",
    "    Y_train = train_df[target]\n",
    "    logreg.fit(train_vec, Y_train)\n",
    "    Y_pred = logreg.predict_proba(test_vec)\n",
    "    logreg_preds[:, idx] = Y_pred[:, 1]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg_submissions_2 = pd.DataFrame(logreg_preds, columns = targets)\n",
    "logreg_submissions_2[\"id\"] = test_df[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_file = \"logreg_2.submission\"\n",
    "logreg_submissions_2.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
